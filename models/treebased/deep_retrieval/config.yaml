# Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


runner:
  train_data_dir: "train_data"
  train_reader_path: "fake_reader" # importlib format
  use_gpu: False
  use_auc: False
  train_batch_size: 2
  epochs: 1
  print_interval: 1
  #model_init_path: "output_model/0" # init model
  model_save_path: "output_model_dr"
  em_execution_interval: 4
  test_data_dir: "test_data"
  infer_reader_path: "fake_infer_reader" # importlib format
  infer_batch_size: 2
  infer_load_path: "output_model_dr"
  infer_start_epoch: 0
  infer_end_epoch: 1
  item_input_file: index/item_demo.txt
  item_output_proto: index/graph_item.proto


# hyper parameters of user-defined network
hyper_parameters:
  # optimizer config
  optimizer:
    class: Adam
    learning_rate: 0.001
    strategy: async
  # user-defined <key, value> pairs
  width: 3
  height: 4 # 8    # 25 in paper
  beam_search_num: 4    # item_path_volume * 4 should be larger than item_path_volume
  item_path_volume: 10 #8 
  user_embedding_size: 2
  use_multi_task_learning: True
  multi_task_layer_size: [128,128,128]
  pernalize_path_to_item_count: False
  item_count: 10000

# when setting item_path_volume & beam_search_num & height, we should pay attention to the flowing tips:
  ## 1、paths for per item;
  ## 2、each user get paths*items posibility paths for each layer
  ## 3、when beamSearch used in recall, nums of beamSearch should be beamSearch*4, it shall be bigger than item_path_volume;
  ## 4、when rerank, we get item_path_volume for each item; or topK path for each item; we set topK==item_path_volume;
  ## 5、when rerank, we get item_path_volume for each item; which should be smaller than (beamSearch*4) get in recall;
  ## 6、when recall; we get (beamSearch*4) in each layer, which should be smaller than the height in each layer;
  ## 7、we expand each node's size to sizeof(items*item_path_volume); especially in userEmbedding input layer; so concat in the same size with following layers' nodes;
